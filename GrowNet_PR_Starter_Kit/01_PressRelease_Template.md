# FOR IMMEDIATE RELEASE
**Date:** 2025-10-07

**GrowNet Unveils Growth‑Capable Neural Architecture for Continual Learning**

**Bayonne, NJ** — GrowNet, an open research effort led by software engineer and entrepreneur Nektarios Kalogridis, today announced an approach to neural networks that **grow structure on demand** when confronted with novel data. Instead of endlessly fine‑tuning a static model, GrowNet allocates new capacity—at the level of slots, layers, or regions—when a principled trigger says specialization will outperform adaptation.

“Most models are static. GrowNet asks: what if the architecture itself could evolve as the world changes?” said Kalogridis. “Our Golden Rule is simple: grow if (and only if) specialization’s expected utility beats further adaptation.”

GrowNet emphasizes:
- **Novelty‑triggered growth** with a formal decision rule.
- **Traceable evolution** via logged growth events and measurable utility.
- **Modularity** so new capacity is auditable, optimizable, and prunable.

Initial milestones include: baseline image benchmarks, a Morse‑code signal task to stress novelty detection, and ablations on growth thresholds. The codebase and docs are public at https://github.com/nectario/grownet.

**About GrowNet**
GrowNet is a research project exploring growth‑capable neural architectures for real‑world continual learning. The project is open, iterative, and designed to make model structure *explainably* evolve with data.

**Media Contact**
press@nektron.ai  •  Bayonne, NJ  •  https://github.com/nectario/grownet

— END —
